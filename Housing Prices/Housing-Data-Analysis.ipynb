{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing A lot of Stuff \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor,StackingRegressor,GradientBoostingRegressor\n",
    "from sklearn.linear_model import LassoCV,RidgeCV,ElasticNetCV\n",
    "from sklearn.svm import SVR\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "import lightgbm as lbg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data\n",
    "train=pd.read_csv('data/train.csv',index_col='Id')\n",
    "test=pd.read_csv('data/test.csv',index_col='Id')\n",
    "y=train['SalePrice']\n",
    "X=train.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Dictionary of the Missing Values and dropping columns with too many missing values\n",
    "def missing(X):\n",
    "    missing_cols={}\n",
    "    for i in range(len(X.columns)):\n",
    "        if X.iloc[:,i].isnull().sum()>0:\n",
    "            missing_cols[X.iloc[:,i].name]=X.iloc[:,i].isnull().sum()        \n",
    "    return missing_cols\n",
    "X.drop(['Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MSZoning': 4,\n",
       " 'Utilities': 2,\n",
       " 'Exterior1st': 1,\n",
       " 'Exterior2nd': 1,\n",
       " 'MasVnrType': 24,\n",
       " 'Electrical': 1,\n",
       " 'KitchenQual': 1,\n",
       " 'Functional': 2,\n",
       " 'SaleType': 1,\n",
       " 'SalePrice': 1459}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Manually Fill Important Missing Values\n",
    "#These columns have NaN for features the houses dont have. So I am adding None to them.\n",
    "null_cats=['BsmtQual', 'BsmtCond','BsmtExposure', 'BsmtFinType1','BsmtFinType2',\n",
    "           'GarageType','GarageFinish','GarageQual', 'GarageCond']\n",
    "for f in null_cats:\n",
    "    X[f].fillna('None',inplace=True)\n",
    "    \n",
    "#These columns should be 0 for NaN values\n",
    "null_nums=['MasVnrArea' ,'GarageYrBlt', 'GarageArea', \n",
    "           'GarageCars','BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath']\n",
    "for f in null_nums:\n",
    "    X[f].fillna(0,inplace=True)\n",
    "    \n",
    "X['LotFrontage']=X.groupby('Neighborhood')['LotFrontage'].transform(lambda x:x.fillna(x.median()))\n",
    "missing(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fill the Remaining missing values with the imputer, median and most_frequent are used so that outliers do not affect this.\n",
    "num_cols = X.select_dtypes([np.int64,np.float64]).columns\n",
    "cat_cols = X.select_dtypes([object]).columns\n",
    "\n",
    "\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "X_num=X[num_cols]\n",
    "\n",
    "X_numeric=pd.DataFrame(imp_mean.fit_transform(X_num))\n",
    "X_numeric.columns=X_num.columns\n",
    "X_numeric.index=X_num.index\n",
    "\n",
    "imp_most = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "X_cat=X[cat_cols]\n",
    "\n",
    "X_categorical=pd.DataFrame(imp_most.fit_transform(X_cat))\n",
    "X_categorical.columns=X_cat.columns\n",
    "X_categorical.index=X_cat.index\n",
    "\n",
    "X=pd.concat([X_numeric,X_categorical],axis=1)\n",
    "missing(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LabelEncoding All the Categories\n",
    "label=LabelEncoder()\n",
    "for feat in cat_cols:\n",
    "    X[feat]=label.fit_transform(X[feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlier Detection and Removal\n",
    "train=X[:1460]\n",
    "def outliers(x, y=y, top=5):\n",
    "    lof = LocalOutlierFactor(n_neighbors=50, contamination=0.1)\n",
    "    x_ =np.array(x).reshape(-1,1)\n",
    "    preds = lof.fit_predict(x_)\n",
    "    lof_scr = lof.negative_outlier_factor_\n",
    "    out_idx = pd.Series(lof_scr).sort_values()[:top].index\n",
    "    return out_idx\n",
    "outs1 = outliers(train['OverallQual'], top=5)\n",
    "outs2 = outliers(train['GrLivArea'],top=5)\n",
    "outs=outs1.append(outs2)\n",
    "X.drop(outs,inplace=True)\n",
    "y.drop(outs,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Standard Scaler \n",
    "X_scaled=pd.DataFrame(StandardScaler().fit_transform(X))\n",
    "X_scaled.columns=X.columns\n",
    "X_scaled.index=X.index\n",
    "X_scaled\n",
    "\n",
    "#Applying log to SalePrice to normalise its distribution.\n",
    "y=np.log(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into train and test sets according to kaggle\n",
    "X_scaled.drop('SalePrice',inplace=True,axis=1)\n",
    "train=X_scaled[:1451]\n",
    "test=X_scaled[1451:]\n",
    "\n",
    "#Creating a train test split for creating a model\n",
    "X_train,X_test,y_train,y_test=train_test_split(train, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this model uses both stacking and blending approach. Hyperparameter isnt done so that can still improve this models accuracy\n",
    "def model(X_train,y_train,X_test):\n",
    "    #Single Models for Blending Aprroach\n",
    "    las=LassoCV(max_iter=1e7,)\n",
    "    rid=RidgeCV()\n",
    "    enr=ElasticNetCV(max_iter=1e7)\n",
    "    gbr=GradientBoostingRegressor()\n",
    "    svm=SVR(C= 20, epsilon= 0.008, gamma=0.0003)\n",
    "    xgb1=XGBRegressor(objective='reg:squarederror',learning_rate=0.02,n_estimators=3000,subsample=0.7,reg_alpha=0.00006)\n",
    "    lgbm=lbg.LGBMRegressor(boosting_type='gbdt',objective='regression',n_estimators=3000,learning_rate=0.01,max_bin=200,\n",
    "                           bagging_fraction=0.75,bagging_freq=5,feature_fraction=0.2)\n",
    "    \n",
    "    estimators=[('ridge', rid),('lasso',las),('ENR',enr),('GBR',gbr),('SVR',svm),('XGB',xgb1),('LGBM',lgbm)]\n",
    "    \n",
    "    #The Stacked Model\n",
    "    stack_model=StackingRegressor(estimators=estimators,final_estimator=xgb1)\n",
    "    stack_model.fit(X_train,y_train)\n",
    "    y_stack=stack_model.predict(X_test)\n",
    "    \n",
    "    #Linear Blending of all models including the stacked one\n",
    "    las.fit(X_train,y_train)\n",
    "    rid.fit(X_train,y_train)\n",
    "    enr.fit(X_train,y_train)\n",
    "    gbr.fit(X_train,y_train)\n",
    "    svm.fit(X_train,y_train)\n",
    "    xgb1.fit(X_train,y_train)\n",
    "    lgbm.fit(X_train,y_train)\n",
    "    y1=las.predict(X_test)\n",
    "    y2=rid.predict(X_test)\n",
    "    y3=enr.predict(X_test)\n",
    "    y4=gbr.predict(X_test)\n",
    "    y5=svm.predict(X_test)\n",
    "    y6=xgb1.predict(X_test)\n",
    "    y7=lgbm.predict(X_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Blending all the results\n",
    "    y_pred=0.1*y1+0.1*y2+0.1*y3+0.1*y4+0.1*y5+0.1*y6+0.1*y7+0.3*y_stack\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08693963582477862"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model(X_train,y_train,X_test) #Model's performance on test data\n",
    "mean_absolute_error(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.04929923062855886"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model(train,y,train)  #Models's Performance on training data. \n",
    "mean_absolute_error(y_pred,y)#This helps in understanding if the model has any bias or variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    }
   ],
   "source": [
    "result=model(train,y,test) #Making the final predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=pd.read_csv('data/sample_submission.csv',index_col=None)  #Creating a submission file\n",
    "res['SalePrice']=np.floor(np.exp(result))\n",
    "res.to_csv('Submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
